# üöÄ AI PR Reviewer ‚Äî Implementation Roadmap

> **Timeline**: 20 days | **Effort**: ~100-120 hours

---

## What Makes This 10/10

| Differentiator | Why It Matters |
|----------------|----------------|
| üîí **Privacy-First** | Ollama support = runs on private repos without sending code to OpenAI |
| üß† **Hybrid Retrieval** | Vector + keyword search beats pure embedding approaches |
| üìä **Feedback Loop** | Learns from üëç/üëé reactions ‚Äî shows product thinking |
| üîê **Security Focus** | Catches secrets, SQL injection, not just style issues |
| üìà **Live Dashboard** | Visual proof of impact ‚Äî interviewers love this |
| üê≥ **Production Ready** | Dockerized, cached, rate-limited ‚Äî not a toy |

---

## Overview

```mermaid
gantt
    title Implementation Timeline (20 Days)
    dateFormat  YYYY-MM-DD
    section Phase 1: Foundation
    GitHub Bot Setup       :p1a, 2026-01-18, 1d
    Basic LLM Review       :p1b, after p1a, 1d
    section Phase 2: RAG Pipeline
    Repo Cloning + Cache   :p2a, after p1b, 1d
    Tree-sitter Parsing    :p2b, after p2a, 2d
    ChromaDB + Embeddings  :p2c, after p2b, 2d
    Hybrid Retrieval       :p2d, after p2c, 1d
    section Phase 3: Intelligence
    Security Scanner       :p3a, after p2d, 2d
    Confidence + Inline    :p3b, after p3a, 2d
    Ollama Integration     :p3c, after p3b, 2d
    section Phase 4: Production
    Feedback Loop          :p4a, after p3c, 1d
    Dashboard UI           :p4b, after p4a, 2d
    Docker + Deploy        :p4c, after p4b, 1d
    section Phase 5: Polish
    Evaluation Suite       :p5a, after p4c, 2d
    Demo + Documentation   :p5b, after p5a, 1d
```

---

## Phase 1: The Foundation (Days 1-2)
**Goal**: Bot comments on a PR using GPT-4

### Day 1: GitHub App Setup

| Task | Details | Est. Time |
|------|---------|-----------|
| ‚òê Register GitHub App | Go to github.com/settings/apps/new | 30 min |
| ‚òê Set Permissions | Read: Code, Contents. Write: Pull Requests, Issues | 15 min |
| ‚òê Generate Private Key | Download `.pem` file, store securely | 10 min |
| ‚òê Set up Smee.io | Create channel at smee.io/new | 10 min |
| ‚òê Install Probot | `npm install probot smee-client` | 15 min |
| ‚òê Configure `.env` | `APP_ID`, `PRIVATE_KEY`, `WEBHOOK_SECRET`, `SMEE_URL` | 20 min |
| ‚òê Test webhook | Open a PR, verify event received | 30 min |

**Files to create/modify**:
- `src/index.js` ‚Äî Probot entry point
- `src/github/webhooks.js` ‚Äî Event handlers
- `.env` ‚Äî Credentials

**Checkpoint ‚úì**: Bot receives webhook events when PR is opened

---

### Day 2: Basic LLM Integration

| Task | Details | Est. Time |
|------|---------|-----------|
| ‚òê Install OpenAI SDK | `npm install openai` | 5 min |
| ‚òê Create LLM abstraction | Provider-agnostic interface (OpenAI, Ollama) | 45 min |
| ‚òê Fetch PR diff | Use `octokit.pulls.get({ mediaType: diff })` | 30 min |
| ‚òê Build basic prompt | "Review this diff: {diff}" | 30 min |
| ‚òê Post comment | `octokit.issues.createComment()` | 30 min |
| ‚òê End-to-end test | Open PR ‚Üí Bot comments ‚Üí Verify | 30 min |

**LLM Abstraction** (future-proofs for Ollama):
```javascript
// src/llm/provider.js
class LLMProvider {
  async chat(messages, options) { throw new Error('Not implemented'); }
  async embed(text) { throw new Error('Not implemented'); }
}

class OpenAIProvider extends LLMProvider { /* ... */ }
class OllamaProvider extends LLMProvider { /* ... */ }  // Day 11-12
```

**Files to create**:
- `src/llm/provider.js` ‚Äî Abstract LLM interface
- `src/llm/openai.js` ‚Äî OpenAI implementation
- `src/review/diffParser.js` ‚Äî Parse diff from PR
- `src/review/generator.js` ‚Äî Generate review
- `src/github/comments.js` ‚Äî Post comments

**Checkpoint ‚úì**: Bot posts an AI review on any PR

---

## Phase 2: The RAG Pipeline (Days 3-8)
**Goal**: Bot understands code context beyond the diff

### Day 3: Repo Cloning with Cache

| Task | Details | Est. Time |
|------|---------|-----------|
| ‚òê Install simple-git | `npm install simple-git` | 5 min |
| ‚òê Create cloner module | Clone to `/tmp/pr-reviewer/{owner}/{repo}` | 1 hr |
| ‚òê Handle auth | Use GitHub App installation token | 30 min |
| ‚òê **Add repo cache** | Reuse clones across PRs, git pull instead of fresh clone | 1 hr |
| ‚òê Cleanup logic | LRU eviction when cache > 5GB | 30 min |
| ‚òê Test cloning | Verify incremental updates work | 30 min |

**Cache Strategy**:
```javascript
// Don't re-clone for every PR
const repoPath = `/tmp/pr-reviewer/${owner}/${repo}`;
if (await fs.exists(repoPath)) {
  await git.pull();  // Fast incremental update
} else {
  await git.clone();
}
```

**Files to create**:
- `src/git/cloner.js`
- `src/git/cache.js` ‚Äî LRU cache manager

---

### Days 4-5: Code Parsing with Tree-sitter

| Task | Details | Est. Time |
|------|---------|-----------|
| ‚òê Install Tree-sitter | `npm install tree-sitter tree-sitter-{javascript,typescript,python,go,rust}` | 15 min |
| ‚òê Create parser module | Initialize parsers for each language | 1 hr |
| ‚òê Write AST walker | Extract functions, classes, imports | 3 hr |
| ‚òê **Extract call graph** | Track function calls for better retrieval | 2 hr |
| ‚òê Create code chunker | Split into chunks with metadata | 2 hr |
| ‚òê Handle edge cases | Empty files, syntax errors, files > 10KB | 1.5 hr |
| ‚òê Test parsing | Verify functions extracted correctly | 1 hr |

**Chunk Format** (enhanced with relationships):
```javascript
{
  id: "src/utils/auth.js::validateToken",
  type: "function",
  name: "validateToken",
  filePath: "src/utils/auth.js",
  startLine: 45,
  endLine: 67,
  content: "function validateToken(token) { ... }",
  language: "javascript",
  calls: ["jwt.verify", "logger.error"],  // NEW: call graph
  calledBy: ["middleware/auth.js::authMiddleware"]  // NEW
}
```

**Supported Languages**: JavaScript, TypeScript, Python, Go, Rust

**Files to create**:
- `src/parsing/treeSitter.js` ‚Äî Multi-language parser
- `src/parsing/callGraph.js` ‚Äî Extract function calls
- `src/utils/codeChunker.js` ‚Äî Chunk extraction

---

### Days 6-7: Vector Store & Embeddings

| Task | Details | Est. Time |
|------|---------|-----------|
| ‚òê Set up ChromaDB | `docker-compose up -d` | 30 min |
| ‚òê Install client | `npm install chromadb` | 5 min |
| ‚òê Create vector store module | CRUD for collections | 1.5 hr |
| ‚òê Create embeddings module | OpenAI `text-embedding-3-small` | 1 hr |
| ‚òê **Add embedding cache** | Don't re-embed unchanged files | 1.5 hr |
| ‚òê Build indexer | Orchestrate: clone ‚Üí parse ‚Üí embed ‚Üí store | 2 hr |
| ‚òê Test indexing | Verify embeddings stored correctly | 1 hr |

**Embedding Cache** (saves $$ and time):
```javascript
// src/rag/embeddingCache.js
const cache = new Map();  // filePath:hash -> embedding

async function getEmbedding(chunk) {
  const hash = crypto.hash(chunk.content);
  if (cache.has(`${chunk.filePath}:${hash}`)) {
    return cache.get(`${chunk.filePath}:${hash}`);
  }
  const embedding = await openai.embeddings.create({ input: chunk.content });
  cache.set(`${chunk.filePath}:${hash}`, embedding);
  return embedding;
}
```

**Files to create**:
- `src/rag/embeddings.js` ‚Äî OpenAI embeddings
- `src/rag/embeddingCache.js` ‚Äî Content-hash cache
- `src/rag/vectorStore.js` ‚Äî ChromaDB operations
- `src/rag/indexer.js` ‚Äî Full indexing pipeline

---

### Day 8: Hybrid Retrieval

| Task | Details | Est. Time |
|------|---------|-----------|
| ‚òê Implement vector search | ChromaDB similarity query | 1 hr |
| ‚òê **Add keyword search** | BM25 or simple text matching | 1.5 hr |
| ‚òê **Combine results** | RRF (Reciprocal Rank Fusion) | 1 hr |
| ‚òê **Add call-graph retrieval** | Fetch callers/callees of modified functions | 1.5 hr |
| ‚òê Test retrieval quality | Measure relevance on test queries | 1 hr |

**Why Hybrid?** Vector search misses exact function names; keyword search misses semantic similarity. Combine both:

```javascript
// src/rag/retriever.js
async function retrieve(query, k = 10) {
  const vectorResults = await chromadb.query(query, k);
  const keywordResults = await bm25Search(query, k);
  return reciprocalRankFusion(vectorResults, keywordResults);
}
```

**Files to create**:
- `src/rag/retriever.js` ‚Äî Hybrid retrieval
- `src/rag/bm25.js` ‚Äî Keyword search

**Checkpoint ‚úì**: Given a code snippet, retriever returns semantically + lexically similar functions

---

## Phase 3: Intelligence Layer (Days 9-14)
**Goal**: Catch real bugs, not just style issues

### Days 9-10: Security Scanner

| Task | Details | Est. Time |
|------|---------|-----------|
| ‚òê Create secret scanner | Regex for API keys, passwords, tokens | 2 hr |
| ‚òê **Add SQL injection detector** | Pattern match unsafe queries | 1.5 hr |
| ‚òê **Add XSS detector** | Find unescaped user input in HTML | 1.5 hr |
| ‚òê Integrate into pipeline | Run scans before LLM, add findings to prompt | 1 hr |
| ‚òê Add rate limiter | Exponential backoff for API calls | 1 hr |
| ‚òê Test security scanning | Verify known vulnerabilities caught | 1 hr |

**Security Patterns**:
```javascript
const SECURITY_PATTERNS = {
  secrets: [
    /ghp_[a-zA-Z0-9]{36}/g,           // GitHub PAT
    /sk-[a-zA-Z0-9]{48}/g,            // OpenAI key
    /AKIA[0-9A-Z]{16}/g,              // AWS key
    /(?:password|secret|key)['"]?\s*[:=]\s*['"][^'"]{8,}['"]/gi,
  ],
  sqlInjection: [
    /execute\s*\(\s*['"`].*\$\{.*\}.*['"`]\s*\)/gi,  // String interpolation in SQL
    /query\s*\(\s*['"`].*\+.*['"`]\s*\)/gi,          // String concat in SQL
  ],
  xss: [
    /innerHTML\s*=\s*[^;]*\$/gi,      // Dynamic innerHTML
    /dangerouslySetInnerHTML/gi,       // React footgun
  ]
};
```

**Files to create**:
- `src/security/secretScanner.js`
- `src/security/vulnScanner.js` ‚Äî SQL injection, XSS
- `src/utils/rateLimiter.js`

---

### Days 11-12: Confidence Scoring & Inline Suggestions

| Task | Details | Est. Time |
|------|---------|-----------|
| ‚òê Modify prompt | Ask LLM to rate confidence 0-100 | 1 hr |
| ‚òê Parse structured output | Extract JSON response | 1 hr |
| ‚òê Filter low-confidence | Don't post if < 50% confidence | 30 min |
| ‚òê **Add severity levels** | üî¥ Critical, üü° Warning, üîµ Suggestion | 1 hr |
| ‚òê Format as GitHub suggestions | Use ```suggestion syntax | 1.5 hr |
| ‚òê Post as review comments | Use `pulls.createReview` with line comments | 1.5 hr |
| ‚òê Test inline experience | Verify one-click apply works | 30 min |

**Structured Output Prompt**:
```
Analyze this code change. For each issue found:
1. Specify the exact line number
2. Rate severity: CRITICAL (bugs/security), WARNING (likely issues), SUGGESTION (improvements)
3. Rate confidence 0-100
4. Provide the fixed code if applicable

Return JSON:
{
  "comments": [{
    "line": 42,
    "severity": "CRITICAL",
    "confidence": 92,
    "message": "Possible SQL injection vulnerability",
    "suggestion": "const result = await db.query(sql, [userId]);"
  }]
}
```

**GitHub Suggestion Format**:
````markdown
üî¥ **Critical** (92% confidence)

Possible SQL injection vulnerability

```suggestion
const result = await db.query(sql, [userId]);
```
````

**Checkpoint ‚úì**: Bot posts inline suggestions with severity badges

---

### Days 13-14: Ollama Integration (Privacy Mode)

| Task | Details | Est. Time |
|------|---------|-----------|
| ‚òê Install Ollama | `curl -fsSL https://ollama.ai/install.sh \| sh` | 15 min |
| ‚òê Pull models | `ollama pull llama3.1:8b` and `ollama pull nomic-embed-text` | 30 min |
| ‚òê Implement OllamaProvider | Extend LLMProvider interface | 2 hr |
| ‚òê Implement local embeddings | Use `nomic-embed-text` | 1.5 hr |
| ‚òê Add config toggle | `LLM_PROVIDER=ollama` in `.env` | 30 min |
| ‚òê Benchmark quality | Compare Ollama vs OpenAI on test PRs | 2 hr |
| ‚òê Document trade-offs | Speed vs quality vs cost | 1 hr |

**Why This Matters**: 
- Private/enterprise repos can't send code to OpenAI
- Free to run (just GPU cost)
- Shows you think about real-world deployment

**Ollama Provider**:
```javascript
// src/llm/ollama.js
class OllamaProvider extends LLMProvider {
  async chat(messages, options = {}) {
    const response = await fetch('http://localhost:11434/api/chat', {
      method: 'POST',
      body: JSON.stringify({
        model: options.model || 'llama3.1:8b',
        messages,
        stream: false
      })
    });
    return response.json();
  }

  async embed(text) {
    const response = await fetch('http://localhost:11434/api/embeddings', {
      method: 'POST',
      body: JSON.stringify({ model: 'nomic-embed-text', prompt: text })
    });
    return response.json();
  }
}
```

**Files to create**:
- `src/llm/ollama.js` ‚Äî Local LLM provider

**Checkpoint ‚úì**: Bot works completely offline with Ollama

---

## Phase 4: Production Features (Days 15-17)
**Goal**: Make it actually usable

### Day 15: Feedback Loop

| Task | Details | Est. Time |
|------|---------|-----------|
| ‚òê Add reaction handler | Listen for üëç/üëé on bot comments | 1.5 hr |
| ‚òê Store feedback | SQLite table: `{comment_id, reaction, pr_url, timestamp}` | 1 hr |
| ‚òê **Calculate helpful rate** | % of comments with üëç | 30 min |
| ‚òê **Tune confidence threshold** | Raise threshold if too many üëé | 1 hr |
| ‚òê Add "Teach the bot" command | `/pr-reviewer ignore this-pattern` | 1.5 hr |

**Why This Matters**: Shows product maturity. Interviewers will ask "how do you know it's good?"

**Feedback Schema**:
```sql
CREATE TABLE feedback (
  id INTEGER PRIMARY KEY,
  comment_id TEXT,
  pr_url TEXT,
  reaction TEXT,  -- 'thumbs_up', 'thumbs_down'
  comment_text TEXT,
  created_at TIMESTAMP
);
```

**Files to create**:
- `src/feedback/collector.js` ‚Äî Reaction handler
- `src/feedback/db.js` ‚Äî SQLite storage
- `data/feedback.db` ‚Äî SQLite database

---

### Days 16-17: Dashboard UI

| Task | Details | Est. Time |
|------|---------|-----------|
| ‚òê Create Express server | Serve dashboard at `/dashboard` | 1 hr |
| ‚òê **Design stats page** | Reviews today, avg confidence, helpful rate | 2 hr |
| ‚òê **Add charts** | Chart.js for trends over time | 2 hr |
| ‚òê **Show recent reviews** | Table with PR links, severity breakdown | 2 hr |
| ‚òê **Add cost tracker** | OpenAI API spend per day | 1 hr |
| ‚òê Style with Tailwind | Make it look premium | 1.5 hr |

**Dashboard Metrics**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  üöÄ PR Reviewer Dashboard                                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Reviews     ‚îÇ Helpful Rate ‚îÇ Avg Latency ‚îÇ Cost Today      ‚îÇ
‚îÇ 47 today    ‚îÇ 78% üëç       ‚îÇ 4.2s        ‚îÇ $0.83           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ [üìà 7-day trend chart]                                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Recent Reviews                                              ‚îÇ
‚îÇ ‚îú‚îÄ user/repo#123: 3 issues (1 üî¥, 2 üü°) ‚Äî 2 min ago        ‚îÇ
‚îÇ ‚îú‚îÄ org/project#456: 1 issue (1 üîµ) ‚Äî 15 min ago           ‚îÇ
‚îÇ ‚îî‚îÄ team/app#789: 0 issues ‚úì ‚Äî 1 hour ago                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Files to create**:
- `src/dashboard/server.js` ‚Äî Express + routes
- `src/dashboard/views/index.html` ‚Äî Dashboard UI
- `src/dashboard/public/` ‚Äî Static assets

**Checkpoint ‚úì**: Live dashboard shows real-time stats

---

### Day 18: Docker & Deployment

| Task | Details | Est. Time |
|------|---------|-----------|
| ‚òê Create Dockerfile | Multi-stage build for production | 1 hr |
| ‚òê Update docker-compose | Add app service alongside ChromaDB | 30 min |
| ‚òê Add health checks | `/health` endpoint | 30 min |
| ‚òê **Write deployment guide** | Railway/Render/VPS instructions | 1.5 hr |
| ‚òê Add GitHub Actions | CI for linting + tests | 1 hr |
| ‚òê Test full deployment | Verify works end-to-end on fresh machine | 1 hr |

**Dockerfile**:
```dockerfile
FROM node:20-slim AS builder
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production

FROM node:20-slim
WORKDIR /app
COPY --from=builder /app/node_modules ./node_modules
COPY . .

ENV NODE_ENV=production
EXPOSE 3000
CMD ["node", "src/index.js"]
```

**Files to create/modify**:
- `Dockerfile`
- `docker-compose.yml` ‚Äî Add app service
- `.github/workflows/ci.yml` ‚Äî GitHub Actions

**Checkpoint ‚úì**: `docker-compose up` runs everything

---

## Phase 5: Evaluation & Demo (Days 19-20)
**Goal**: Prove it works with numbers

### Day 19: Evaluation Suite

| Task | Details | Est. Time |
|------|---------|-----------|
| ‚òê Collect test PRs | 30 PRs with known bugs from open-source repos | 2 hr |
| ‚òê Create ground truth | Label expected issues in each PR | 2 hr |
| ‚òê Build test harness | Script to run bot on all test PRs | 2 hr |
| ‚òê Calculate metrics | Precision, Recall, F1, False Positive Rate | 1 hr |
| ‚òê **Compare providers** | OpenAI vs Ollama accuracy | 1 hr |
| ‚òê Document results | Table of metrics + example outputs | 1 hr |

**Evaluation Categories**:
```javascript
const TEST_PRS = [
  // Security issues
  { repo: "OWASP/WebGoat", pr: 1234, category: "security", knownIssues: [...] },
  
  // Logic bugs
  { repo: "apache/kafka", pr: 5678, category: "bugs", knownIssues: [...] },
  
  // Performance issues
  { repo: "nodejs/node", pr: 9012, category: "performance", knownIssues: [...] },
];
```

**Files to create**:
- `scripts/evaluate.js`
- `test-cases/` ‚Äî Labeled test PRs

---

### Day 20: Demo & Documentation

| Task | Details | Est. Time |
|------|---------|-----------|
| ‚òê Create demo repo | With intentionally flawed PRs | 1 hr |
| ‚òê Record demo video | 90-second screen recording | 1.5 hr |
| ‚òê Write polished README | Features, architecture diagram, screenshots | 2 hr |
| ‚òê Add GIF preview | Bot catching a real bug | 30 min |
| ‚òê Write CONTRIBUTING.md | How others can contribute | 30 min |
| ‚òê **Publish to GitHub Marketplace** | Make it installable | 1 hr |

**README Structure**:
```markdown
# ü§ñ AI PR Reviewer

> Catch bugs before your teammates do.

![Demo GIF](./docs/demo.gif)

## ‚ú® Features
- üîí Privacy-first: Runs locally with Ollama
- üß† Context-aware: RAG over your entire codebase
- üîê Security: Catches secrets, SQL injection, XSS
- üìä Learns: Thumbs up/down feedback loop

## üìä Benchmark Results
| Metric | OpenAI | Ollama |
|--------|--------|--------|
| Precision | 74% | 68% |
| Recall | 52% | 48% |
| Latency | 4.2s | 8.1s |
| Cost/PR | $0.08 | $0.00 |

## üöÄ Quick Start
[...]
```

**Checkpoint ‚úì**: Polished project ready for portfolio

---

## Quick Reference: Commands

```bash
# Development
npm run dev                    # Start bot with hot reload
npm run webhook                # Start Smee webhook forwarding
docker-compose up -d           # Start ChromaDB + app

# Privacy Mode
ollama serve                   # Start local LLM
LLM_PROVIDER=ollama npm run dev

# Indexing
npm run index -- --repo owner/repo  # Manually index a repo

# Testing
npm run test                   # Run unit tests
npm run evaluate               # Run evaluation suite

# Dashboard
open http://localhost:3000/dashboard

# Utilities
npm run clean-tmp              # Clean /tmp directories
npm run feedback-report        # Show helpful rate stats
```

---

## Architecture

```mermaid
flowchart TD
    subgraph GitHub
        PR[Pull Request] --> WH[Webhook]
    end
    
    subgraph "PR Reviewer"
        WH --> Handler[Event Handler]
        Handler --> Clone[Repo Cloner]
        Clone --> Cache[(Repo Cache)]
        Clone --> Parser[Tree-sitter]
        Parser --> Indexer[Code Indexer]
        
        Handler --> Diff[Diff Parser]
        Diff --> Security[Security Scanner]
        
        Indexer --> VDB[(ChromaDB)]
        Diff --> Retriever[Hybrid Retriever]
        Retriever --> VDB
        
        Security --> LLM{LLM Provider}
        Retriever --> LLM
        LLM --> OpenAI[OpenAI GPT-4]
        LLM --> Ollama[Ollama Local]
        
        LLM --> Formatter[Comment Formatter]
        Formatter --> Review[GitHub Review]
    end
    
    subgraph Feedback
        Review --> Reactions[üëç/üëé]
        Reactions --> FDB[(Feedback DB)]
        FDB --> Dashboard[üìä Dashboard]
    end
```

---

## Risk Mitigation

| Risk | Mitigation |
|------|------------|
| Rate limited by GitHub | Exponential backoff, cache installation tokens |
| Rate limited by OpenAI | Batch embeddings, embedding cache, use Ollama |
| Large repos timeout | 5-min timeout, skip files > 10KB, incremental indexing |
| Secrets leaked to LLM | Scan diff before sending, redact matches |
| ChromaDB crashes | Docker health checks, auto-restart |
| Low quality reviews | Confidence threshold + user feedback loop |

---

## Success Criteria

| Metric | Target |
|--------|--------|
| Precision | > 70% |
| Recall | > 50% |
| Helpful Rate | > 70% (from user feedback) |
| Latency | < 10s per PR |
| Cost | < $0.10 per PR (or $0 with Ollama) |
| Demo | 90-second video showing real bug caught |

---

## File Structure

```
pr-reviewer/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ index.js              # Entry point
‚îÇ   ‚îú‚îÄ‚îÄ github/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ webhooks.js       # Event handlers
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ comments.js       # Post reviews
‚îÇ   ‚îú‚îÄ‚îÄ git/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cloner.js         # Clone repos
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cache.js          # LRU repo cache
‚îÇ   ‚îú‚îÄ‚îÄ parsing/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ treeSitter.js     # AST parsing
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ callGraph.js      # Function relationships
‚îÇ   ‚îú‚îÄ‚îÄ rag/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embeddings.js     # Embedding generation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embeddingCache.js # Content-hash cache
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vectorStore.js    # ChromaDB operations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ indexer.js        # Indexing pipeline
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ retriever.js      # Hybrid search
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ bm25.js           # Keyword search
‚îÇ   ‚îú‚îÄ‚îÄ llm/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ provider.js       # Abstract interface
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ openai.js         # OpenAI provider
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ollama.js         # Ollama provider
‚îÇ   ‚îú‚îÄ‚îÄ security/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ secretScanner.js  # Detect secrets
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vulnScanner.js    # SQL injection, XSS
‚îÇ   ‚îú‚îÄ‚îÄ review/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ diffParser.js     # Parse PR diffs
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ generator.js      # Generate review
‚îÇ   ‚îú‚îÄ‚îÄ feedback/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ collector.js      # Reaction handler
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ db.js             # SQLite storage
‚îÇ   ‚îú‚îÄ‚îÄ dashboard/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ server.js         # Express server
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ views/            # HTML templates
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ rateLimiter.js    # Backoff logic
‚îÇ       ‚îî‚îÄ‚îÄ codeChunker.js    # Split code
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ evaluate.js           # Benchmark suite
‚îú‚îÄ‚îÄ test-cases/               # Labeled PRs
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ feedback.db           # SQLite
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ docker-compose.yml
‚îî‚îÄ‚îÄ package.json
```

---

## What Makes This Interview-Ready

1. **Privacy Story**: "I added Ollama support because enterprise companies can't send proprietary code to OpenAI"

2. **Product Thinking**: "The feedback loop lets users train the model on their codebase's conventions"

3. **Scale Awareness**: "The embedding cache saves 90% of API costs on incremental PRs"

4. **Security Focus**: "It catches secrets before they reach the LLM, and scans for SQL injection"

5. **Measurable Impact**: "I benchmarked against 30 real PRs and achieved 74% precision"

---

## Getting Started

```bash
cd /home/awhvish/Desktop/pr-reviewer
npm install

# Then register your GitHub App at github.com/settings/apps/new
# Set up your .env file and you're ready for Day 1!
```

**Build something impressive! üéØ**
